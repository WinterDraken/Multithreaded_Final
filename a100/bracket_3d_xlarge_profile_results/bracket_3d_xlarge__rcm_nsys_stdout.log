=== FEM GPU Pipeline ===
Mesh file: CPU/bracket_3d_xlarge.msh
Mesh base: bracket_3d_xlarge
Reordering method: rcm
Material: E=200000 MPa, nu=0.3

Parsed 14521 nodes, 80249 elements.
Tet4 elements: 65619
CSR pattern: nDOF=43566, nnz=874212
Allocating GPU memory...
Computing local element stiffness (GPU)...
Assembling global CSR matrix (GPU)...
Assembly complete.
Solving Kx = f in reordered space...
Timing results saved to results/rcm/bracket_3d_xlarge__rcm_results.txt
Done.
Generating '/tmp/nsys-report-b718.qdstrm'
[1/8] [0%                          ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [0%                          ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [0%                          ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [0%                          ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [8%                          ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [=16%                        ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [===24%                      ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [=====32%                    ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [=======39%                  ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [==========47%               ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [============55%             ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [==============63%           ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [================71%         ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [===================79%      ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [====================83%     ] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [========================100%] bracket_3d_xlarge__rcm_nsys.nsys-rep[1/8] [========================100%] bracket_3d_xlarge__rcm_nsys.nsys-rep
[2/8] [0%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [1%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [2%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [3%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [4%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [5%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [6%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [7%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [8%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [9%                          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [10%                         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [11%                         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [12%                         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [13%                         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [14%                         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=15%                        ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=16%                        ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=17%                        ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==18%                       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==19%                       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==20%                       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==21%                       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===22%                      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===23%                      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===24%                      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====25%                     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====26%                     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====27%                     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====28%                     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====29%                    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====30%                    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====31%                    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====32%                    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [======33%                   ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [======34%                   ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [======35%                   ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======36%                  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======37%                  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======38%                  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======39%                  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========40%                 ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========41%                 ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========42%                 ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=========43%                ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=========44%                ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=========45%                ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=========46%                ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==========47%               ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==========48%               ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==========49%               ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===========50%              ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===========51%              ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===========52%              ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===========53%              ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [============54%             ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [============55%             ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [============56%             ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [============57%             ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=============58%            ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=============59%            ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=============60%            ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==============61%           ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==============62%           ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==============63%           ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==============64%           ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===============65%          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===============66%          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===============67%          ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [================68%         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [================69%         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [================70%         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [================71%         ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=================72%        ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=================73%        ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=================74%        ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==================75%       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==================76%       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==================77%       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [==================78%       ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===================79%      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===================80%      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===================81%      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [===================82%      ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====================83%     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====================84%     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [====================85%     ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====================86%    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====================87%    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====================88%    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=====================89%    ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [======================90%   ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [======================91%   ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [======================92%   ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======================93%  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======================94%  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======================95%  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [=======================96%  ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========================97% ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========================98% ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========================99% ] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========================100%] bracket_3d_xlarge__rcm_nsys.sqlite[2/8] [========================100%] bracket_3d_xlarge__rcm_nsys.sqlite
[3/8] Executing 'nvtx_sum' stats report

 Time (%)  Total Time (ns)  Instances     Avg (ns)         Med (ns)        Min (ns)       Max (ns)     StdDev (ns)   Style     Range  
 --------  ---------------  ---------  ---------------  ---------------  -------------  -------------  -----------  -------  ---------
    100.0    1,830,041,979          1  1,830,041,979.0  1,830,041,979.0  1,830,041,979  1,830,041,979          0.0  PushPop  CG_Solver

[4/8] Executing 'osrt_sum' stats report

 Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)   Max (ns)    StdDev (ns)            Name         
 --------  ---------------  ---------  ------------  -------------  --------  -----------  ------------  ----------------------
     92.7    2,300,664,684         34  67,666,608.4  100,275,324.0     4,190  100,358,295  43,903,702.7  poll                  
      6.5      161,460,467        612     263,824.3       14,806.5     3,073   16,415,217     916,376.9  ioctl                 
      0.2        3,837,652        371      10,344.1       10,057.0     3,073       47,492       3,283.2  read                  
      0.1        2,479,927         31      79,997.6        8,102.0     3,632    1,004,038     211,248.7  fopen                 
      0.1        2,180,725          2   1,090,362.5    1,090,362.5    39,670    2,141,055   1,485,903.6  fopen64               
      0.1        2,061,158         10     206,115.8      237,181.0   108,673      269,029      65,406.8  sem_timedwait         
      0.1        1,710,552         67      25,530.6        3,073.0     2,793      483,581      91,990.7  fcntl                 
      0.1        1,485,663          5     297,132.6      176,280.0    10,336      921,346     360,673.0  pthread_rwlock_wrlock 
      0.0        1,125,001         29      38,793.1        9,219.0     7,822      679,416     124,056.3  mmap64                
      0.0        1,069,971         12      89,164.3        8,381.0     3,073      601,194     196,940.8  fread                 
      0.0          699,811        256       2,733.6        2,793.0     2,514        4,191         236.8  pthread_mutex_trylock 
      0.0          479,390          4     119,847.5      108,533.5   101,688      160,635      27,422.6  pthread_create        
      0.0          441,673         27      16,358.3        5,028.0     3,631      286,350      54,064.6  fclose                
      0.0          402,286         14      28,734.7        7,962.0     5,308      257,575      66,416.1  mmap                  
      0.0          372,398         48       7,758.3        6,705.0     4,470       28,216       3,467.0  open64                
      0.0          346,971          1     346,971.0      346,971.0   346,971      346,971           0.0  pthread_cond_wait     
      0.0          282,718          4      70,679.5        6,565.0     5,308      264,280     129,069.6  munmap                
      0.0          205,614         13      15,816.5       13,689.0     3,352       50,007      10,698.8  write                 
      0.0          131,027         31       4,226.7        2,793.0     2,514       51,404       8,756.9  fgets                 
      0.0          122,919         39       3,151.8        2,794.0     2,514        5,867         766.3  fwrite                
      0.0           68,168         24       2,840.3        2,794.0     2,514        3,911         365.4  fflush                
      0.0           61,461          7       8,780.1        9,220.0     3,912       12,012       3,029.3  open                  
      0.0           36,317          2      18,158.5       18,158.5     8,101       28,216      14,223.5  pthread_cond_broadcast
      0.0           27,937          3       9,312.3       10,616.0     5,588       11,733       3,273.4  pipe2                 
      0.0           23,746          8       2,968.3        3,073.0     2,793        3,073         144.6  dup                   
      0.0           18,159          2       9,079.5        9,079.5     6,146       12,013       4,148.6  socket                
      0.0           12,292          1      12,292.0       12,292.0    12,292       12,292           0.0  connect               
      0.0            3,632          1       3,632.0        3,632.0     3,632        3,632           0.0  bind                  
      0.0            3,352          1       3,352.0        3,352.0     3,352        3,352           0.0  listen                

[5/8] Executing 'cuda_api_sum' stats report

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)    Max (ns)    StdDev (ns)                  Name               
 --------  ---------------  ---------  -----------  -----------  ---------  -----------  ------------  ----------------------------------
     34.3      366,479,584     50,006      7,328.7      6,705.0      6,146    3,558,833      25,156.9  cudaLaunchKernel                  
     20.9      223,841,320     10,001     22,381.9     21,511.0     20,393      217,346       4,244.4  cudaMemcpyAsync                   
     15.4      164,915,663     50,005      3,298.0      3,073.0      3,073       41,067       1,352.7  cudaStreamGetCaptureInfo_v2_v11030
     14.4      153,718,994         17  9,042,293.8     14,806.0      9,778  152,533,088  36,976,910.6  cudaMalloc                        
      9.0       96,317,011     10,001      9,630.7      9,498.0      8,939       46,654       2,137.7  cudaStreamSynchronize             
      3.7       39,270,367     10,001      3,926.6      3,632.0      3,352       39,391       1,796.3  cudaEventRecord                   
      1.4       14,763,055         20    738,152.8     35,200.5     10,058   10,254,377   2,297,244.6  cudaFree                          
      0.3        3,505,762      1,156      3,032.7      2,794.0      2,793       26,819       1,420.4  cuGetProcAddress_v2               
      0.2        2,519,874         15    167,991.6     62,299.0     17,041      679,695     200,883.8  cudaMemcpy                        
      0.2        1,641,270          1  1,641,270.0  1,641,270.0  1,641,270    1,641,270           0.0  cudaGetDeviceProperties_v2_v12000 
      0.1        1,285,918          7    183,702.6     12,292.0      9,219      688,635     294,613.7  cudaDeviceSynchronize             
      0.0           66,207         18      3,678.2      3,352.0      3,073        6,705         847.8  cudaEventCreateWithFlags          
      0.0           65,653         18      3,647.4      3,353.0      3,073        8,660       1,258.3  cudaEventDestroy                  
      0.0           36,877          1     36,877.0     36,877.0     36,877       36,877           0.0  cudaMemset                        
      0.0           13,410          4      3,352.5      2,933.5      2,794        4,749         940.2  cuModuleGetLoadingMode            
      0.0           12,013          3      4,004.3      3,911.0      3,632        4,470         426.7  cuInit                            
      0.0           11,174          1     11,174.0     11,174.0     11,174       11,174           0.0  cudaEventQuery                    

[6/8] Executing 'cuda_gpu_kern_sum' stats report

 Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                                                  Name                                                
 --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------------------------------------------------------------
     28.6       91,576,628      5,001   18,311.7   18,752.0    16,320    19,776        921.6  void cusparse::csrmv_v3_kernel<(bool)0, int, int, double, double, double, double, void>(cusparse::K…
     20.2       64,505,643     15,000    4,300.4    4,416.0     3,968     4,545        189.1  void axpy_kernel_val<double, double>(cublasAxpyParamsVal<T1, T1, T2>)                               
     16.4       52,403,360     10,001    5,239.8    5,344.0     4,832     5,536        238.6  void dot_kernel<double, (int)128, (int)0, cublasDotParams<cublasGemvTensor<const double>, cublasGem…
     14.7       47,108,424     10,001    4,710.4    4,864.0     4,352     4,928        219.5  void reduce_1Block_kernel<double, (int)128, (int)7, cublasGemvTensorStridedBatched<double>, cublasG…
     13.6       43,344,111      5,001    8,667.1    8,928.0     8,032     9,984        389.3  void cusparse::csrmv_v3_partition_kernel<(int)256, cusparse::VectorScalarMultiplyPolicy, int, int, …
      6.2       19,687,490      5,000    3,937.5    4,032.0     3,648     4,128        171.4  void scal_kernel_val<double, double>(cublasScalParamsVal<T1, T2>)                                   
      0.2          686,465          1  686,465.0  686,465.0   686,465   686,465          0.0  assembleCSR_atomic_kernel(const double *, const int *, const int *, const int *, double *, int, int…
      0.2          530,177          1  530,177.0  530,177.0   530,177   530,177          0.0  kernelKe_Tet4_3D(const double *, const double *, const double *, const int *, double, double, doubl…

[7/8] Executing 'cuda_gpu_mem_time_sum' stats report

 Time (%)  Total Time (ns)  Count   Avg (ns)   Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     
 --------  ---------------  ------  ---------  --------  --------  --------  -----------  ------------------
     95.4       23,802,128  10,003    2,379.5   2,336.0     2,176   569,569      5,990.5  [CUDA memcpy DtoH]
      4.5        1,117,217      11  101,565.2  19,744.0     8,160   408,929    143,455.3  [CUDA memcpy HtoD]
      0.0            9,120       1    9,120.0   9,120.0     9,120     9,120          0.0  [CUDA memset]     
      0.0            8,576       2    4,288.0   4,288.0     4,032     4,544        362.0  [CUDA memcpy DtoD]

[8/8] Executing 'cuda_gpu_mem_size_sum' stats report

 Total (MB)  Count   Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     
 ----------  ------  --------  --------  --------  --------  -----------  ------------------
     16.431      11     1.494     0.349     0.116     6.994        2.242  [CUDA memcpy HtoD]
      7.422  10,003     0.001     0.000     0.000     6.994        0.070  [CUDA memcpy DtoH]
      6.994       1     6.994     6.994     6.994     6.994        0.000  [CUDA memset]     
      0.697       2     0.349     0.349     0.349     0.349        0.000  [CUDA memcpy DtoD]

Generated:
    /work/09424/jiwoooop/ls6/Multithreaded_Final/a100/bracket_3d_xlarge_profile_results/bracket_3d_xlarge__rcm_nsys.nsys-rep
    /work/09424/jiwoooop/ls6/Multithreaded_Final/a100/bracket_3d_xlarge_profile_results/bracket_3d_xlarge__rcm_nsys.sqlite
